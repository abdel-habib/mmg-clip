{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c258c2ad-1cf2-4aa6-bbd0-1cc5bf5e29ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdel/Documents/mmg-clip/env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6d69170-1bde-46aa-9218-af1458e178f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/emilyalsentzer/Bio_ClinicalBERT\n",
    "model_type = 'emilyalsentzer/Bio_ClinicalBERT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76d90320-0f33-49ca-be37-e66fa04167d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4fd22b5-f18b-49cd-981c-e2e2f3d89480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd184699",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05307cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb4f7b83-4cbf-4b1b-a4e3-088f4f548f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"emilyalsentzer/Bio_ClinicalBERT\",\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.37.2\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 28996\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "032bdbd0-7212-468b-a521-6a687e1da377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "237b232a-ef41-47c9-919b-4d61c0a4a065",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e57927e-44e4-4871-b431-7d8351905892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='emilyalsentzer/Bio_ClinicalBERT', vocab_size=28996, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2a35282-8648-4404-b0d8-42c2200914f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28996"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.get_vocab().items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81608358-9218-4ea0-8346-4225e46d4337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unk_token': '[UNK]',\n",
       " 'sep_token': '[SEP]',\n",
       " 'pad_token': '[PAD]',\n",
       " 'cls_token': '[CLS]',\n",
       " 'mask_token': '[MASK]'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7babebab-b8ff-4cc2-9bde-1d53be0b4cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 'Hello world!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db4d445c-82c8-412c-b674-bd1171e9bdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.tokenize(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c14a11b0-9b11-429f-97e8-cfdb3c77fa6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'world', '!']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2fc66b-3ff2-4ec3-916d-7ef15f03203a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0682a08c-49fb-41d9-8318-25830d92f25c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc36af56-f88b-455f-9a1a-17ecf1084d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform input tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e198f172-295f-440c-aefd-c9da1da6673c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"Hello world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3194c57f-06d3-46d7-bd8e-116584bb7ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 19082, 1362, 106, 102], 'token_type_ids': [0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e789a354-652d-449a-bc7f-ae6513b85473",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"Hello world!\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "214aba55-ac05-4d48-8b81-9fed13f4deeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101, 19082,  1362,   106,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdffb9f0-1983-4b96-9f5d-3c589fde9ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model apply\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30b6a8d9-b878-45fe-9c21-487eb7684ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.1532,  0.6183, -0.2199,  ...,  0.1997,  0.6364, -0.4686],\n",
       "         [-0.0503,  0.1174, -0.0838,  ...,  0.1973,  0.3145, -0.3396],\n",
       "         [ 0.1379,  0.1863, -0.1400,  ...,  0.2266,  0.0506, -0.4840],\n",
       "         [-0.1522,  0.0899, -0.1756,  ...,  0.3008,  0.0847, -0.2710],\n",
       "         [ 0.6556,  1.1622,  0.3298,  ..., -0.0702,  1.3476, -0.7676]]]), pooler_output=tensor([[ 4.7645e-02,  1.1744e-02,  9.9956e-01, -1.0000e+00,  9.9996e-01,\n",
       "          7.5687e-01, -1.7265e-01,  7.4451e-01, -1.4755e-01,  7.3705e-02,\n",
       "          9.9993e-01,  1.0000e+00, -9.3152e-01, -9.9122e-01, -2.3026e-01,\n",
       "         -9.1678e-01,  1.0000e+00, -7.6820e-03, -9.9997e-01,  1.0957e-01,\n",
       "         -1.2149e-01, -9.9830e-01,  1.0776e-01,  9.9897e-01,  7.1062e-02,\n",
       "          7.9029e-02,  1.0000e+00,  9.9997e-01, -3.5269e-02, -3.7762e-02,\n",
       "          6.3934e-02, -9.9997e-01,  9.9904e-01, -9.9999e-01, -1.9132e-02,\n",
       "          2.3128e-02, -2.4202e-01, -1.5514e-02,  8.9748e-01, -9.9713e-01,\n",
       "         -1.9237e-01, -6.9366e-01,  2.1051e-01,  1.8118e-01,  9.9990e-01,\n",
       "         -2.7081e-01, -2.1691e-03,  7.1114e-02, -3.8164e-02,  9.9362e-01,\n",
       "          1.9629e-01,  9.9999e-01, -9.9975e-01,  9.9999e-01,  1.0000e+00,\n",
       "         -4.0837e-03,  1.0000e+00, -1.2731e-01,  3.7379e-02, -1.5829e-01,\n",
       "          7.0087e-02,  4.0697e-02, -5.4448e-01,  7.0072e-02,  1.7768e-01,\n",
       "          9.3192e-02, -9.9269e-01,  1.1229e-01, -2.3864e-02, -6.0689e-02,\n",
       "         -1.1082e-01, -1.1710e-02,  9.9950e-01,  2.3793e-01, -4.0641e-03,\n",
       "          2.1776e-01, -1.4045e-01, -9.9892e-01,  9.9989e-01,  9.9999e-01,\n",
       "          6.1320e-01, -1.0000e+00,  1.0000e+00, -6.8011e-03, -9.0099e-02,\n",
       "          3.1276e-01,  7.1323e-01, -1.0000e+00,  4.8144e-02,  1.5450e-01,\n",
       "          9.9968e-01, -9.9996e-01,  1.4839e-01, -9.9563e-01,  9.9999e-01,\n",
       "          2.0798e-01,  5.6346e-02,  4.9825e-02,  9.9974e-01, -3.3197e-01,\n",
       "         -5.8506e-02,  9.9983e-01, -3.6235e-01,  9.8964e-01,  8.3946e-01,\n",
       "          1.3314e-01,  1.7878e-01, -9.1907e-01,  2.3147e-01, -6.1447e-02,\n",
       "          4.5161e-01,  1.5368e-01, -1.5992e-02,  2.8597e-02,  9.9848e-01,\n",
       "         -6.9752e-01,  1.0000e+00,  7.7041e-01, -1.8647e-01,  9.9998e-01,\n",
       "         -7.5073e-02,  9.9709e-01,  1.0000e+00,  3.4586e-01,  6.9720e-01,\n",
       "          1.2894e-02, -1.0940e-01,  9.9889e-01, -3.1452e-01,  6.7431e-03,\n",
       "          1.4938e-01, -1.0000e+00, -9.8130e-01,  1.0000e+00, -1.0875e-01,\n",
       "          1.0000e+00, -1.0000e+00,  9.9799e-01, -9.9977e-01,  5.2058e-01,\n",
       "         -6.2678e-02, -5.9895e-02, -9.9959e-01, -7.7973e-02,  9.5483e-01,\n",
       "         -8.1221e-02, -9.9962e-01, -6.4657e-01,  1.8277e-01,  4.8726e-02,\n",
       "          9.1234e-02, -7.6307e-02,  2.2108e-01,  9.9974e-01,  9.9973e-01,\n",
       "          9.9953e-01,  9.9988e-01, -9.5669e-02,  4.6813e-01,  9.7573e-01,\n",
       "          9.9995e-01, -1.0000e+00,  6.3721e-01, -9.8685e-01,  9.9681e-01,\n",
       "          9.9944e-01,  1.5617e-01,  8.9197e-01,  1.0000e+00, -8.1516e-02,\n",
       "          1.8066e-01,  6.5087e-02, -8.4791e-02, -3.1329e-01,  1.3137e-02,\n",
       "         -1.1805e-01, -1.5787e-01,  9.9966e-01, -1.0000e+00,  9.6911e-01,\n",
       "          9.4592e-01,  1.1061e-01,  1.5447e-02,  3.0366e-01, -1.0000e+00,\n",
       "         -9.7119e-01, -9.9995e-01, -1.3844e-01,  5.7080e-01,  1.9555e-01,\n",
       "          1.1253e-01, -3.2904e-01, -6.8059e-01,  2.1239e-02, -3.2193e-01,\n",
       "          4.8745e-02,  9.9920e-01, -8.0416e-02,  1.0000e+00, -2.9424e-01,\n",
       "         -1.0000e+00, -6.8333e-01,  9.9958e-01,  4.7940e-01,  1.2472e-01,\n",
       "          1.2062e-01,  9.3205e-02,  4.5995e-02, -6.3015e-01, -9.9992e-01,\n",
       "         -9.8395e-01,  1.1124e-01, -7.2515e-02,  8.0710e-02,  9.9988e-01,\n",
       "          1.8710e-01, -1.2103e-01, -7.4753e-02, -8.7830e-02,  9.9999e-01,\n",
       "         -1.0000e+00,  7.9735e-02, -1.2348e-01, -1.0000e+00, -1.0000e+00,\n",
       "          9.9939e-01,  1.0994e-01, -7.5609e-02, -5.4872e-02, -7.4285e-01,\n",
       "          9.0399e-02,  9.9995e-01,  9.9997e-01, -1.8778e-01, -3.6046e-01,\n",
       "         -9.9998e-01,  9.0797e-01,  1.9713e-01, -9.9948e-01,  8.1081e-02,\n",
       "          1.4146e-02, -1.2657e-01,  3.0694e-01, -9.1406e-01, -1.5010e-01,\n",
       "         -1.3957e-01, -9.9963e-01,  1.2883e-01, -9.2635e-03, -8.1502e-01,\n",
       "         -3.2458e-02, -3.2757e-01, -9.9565e-01,  1.0000e+00, -9.9823e-01,\n",
       "          9.9288e-01,  9.9621e-01, -1.0000e+00, -3.1096e-01, -1.1795e-01,\n",
       "         -1.0789e-01, -9.9999e-01,  2.2379e-01,  2.0607e-01,  6.8894e-02,\n",
       "         -3.4012e-02,  1.0000e+00, -8.2115e-02, -4.2085e-02,  6.7605e-02,\n",
       "         -9.9999e-01,  6.6436e-02, -1.5418e-01,  1.0000e+00,  5.3682e-01,\n",
       "         -3.2454e-02,  9.1342e-01,  2.5160e-01, -9.9998e-01, -9.9998e-01,\n",
       "          9.7893e-01,  9.9818e-01, -1.0000e+00, -4.3736e-02,  1.0000e+00,\n",
       "          8.0067e-01,  1.5925e-01, -9.9954e-01, -9.9889e-01, -1.0000e+00,\n",
       "         -4.7532e-03,  6.9700e-02,  3.3480e-02,  9.9645e-01,  1.0955e-02,\n",
       "          1.0473e-01,  9.9998e-01,  9.9994e-01,  9.1053e-02, -1.1112e-01,\n",
       "         -1.1407e-02, -9.9991e-01, -9.9593e-01,  3.4227e-01, -2.4057e-01,\n",
       "         -9.9980e-01,  1.0000e+00, -9.9999e-01,  1.0000e+00,  9.9959e-01,\n",
       "          9.0243e-01, -1.5637e-01, -1.3419e-01, -9.9950e-01,  4.6749e-03,\n",
       "          9.9998e-01,  9.9734e-01, -4.2741e-03,  1.5906e-03,  9.8984e-01,\n",
       "          1.2950e-02, -8.2434e-02,  5.7316e-02, -5.5936e-03,  3.8788e-03,\n",
       "         -1.8606e-01,  9.9770e-01, -7.8396e-01, -1.0000e+00,  9.9323e-01,\n",
       "          2.7618e-02, -1.0580e-02, -7.3312e-01,  9.1077e-02,  1.0000e+00,\n",
       "          2.9911e-02,  1.0617e-01,  6.0884e-02, -8.8261e-01,  4.1438e-01,\n",
       "          1.9891e-01, -9.9967e-01, -1.3636e-01,  7.5275e-01,  9.9986e-01,\n",
       "         -9.9998e-01,  9.9999e-01, -8.3147e-02,  8.6945e-01,  5.6082e-01,\n",
       "          9.9997e-01, -9.9999e-01, -1.0314e-01,  6.1059e-02, -9.9803e-01,\n",
       "          1.9624e-02,  9.9992e-01,  9.3113e-01,  9.0758e-01,  6.8173e-01,\n",
       "         -2.0433e-02, -8.7157e-02, -2.4990e-01, -9.9904e-01, -1.7978e-04,\n",
       "          8.9303e-01, -8.3955e-03,  9.9895e-01, -3.0131e-02,  1.5709e-01,\n",
       "          1.6560e-01, -9.9951e-01, -1.1616e-01, -4.2496e-01, -9.1325e-01,\n",
       "         -4.3340e-02, -9.3909e-01,  3.0234e-01, -7.3716e-01, -3.4760e-01,\n",
       "          9.9936e-01, -1.1408e-01, -9.9871e-01,  9.2471e-01,  5.0709e-01,\n",
       "          1.0000e+00, -9.9999e-01,  3.6443e-01,  9.9992e-01, -5.9394e-02,\n",
       "         -5.9620e-01, -3.1032e-02, -8.6692e-01, -9.8992e-01,  1.5950e-02,\n",
       "         -1.0000e+00, -4.1261e-02,  1.1138e-01, -1.4927e-01, -2.7779e-01,\n",
       "          1.3557e-02, -8.1533e-02,  9.9975e-01,  2.4254e-04,  4.3660e-03,\n",
       "         -3.4724e-02,  9.9886e-01, -6.7423e-02, -4.9239e-02, -2.6391e-02,\n",
       "         -2.0729e-01,  1.1795e-01,  1.2516e-01,  9.9724e-01,  6.5479e-02,\n",
       "          9.9951e-01, -4.6676e-02, -1.0000e+00,  7.4509e-01, -8.4929e-01,\n",
       "         -9.9920e-01,  4.9841e-02, -9.9999e-01,  1.0000e+00,  9.8685e-01,\n",
       "         -9.2512e-01, -1.1426e-01, -9.9999e-01, -9.9997e-01,  9.3643e-01,\n",
       "          1.6792e-01, -1.7437e-02,  1.2840e-01,  9.5242e-01,  7.0874e-02,\n",
       "         -3.8547e-01,  6.4761e-04,  2.0206e-01, -2.8333e-01, -1.2127e-01,\n",
       "          1.0044e-01, -9.9999e-01,  2.4865e-01,  9.7923e-01, -9.0948e-01,\n",
       "         -8.4619e-01, -9.9921e-01,  8.2638e-01, -3.7493e-02, -2.7035e-03,\n",
       "          9.9737e-01, -1.4489e-01, -1.2509e-01, -9.9380e-01,  9.7958e-01,\n",
       "         -4.0340e-01,  1.5473e-02, -1.7970e-01,  1.8442e-01,  9.9955e-01,\n",
       "         -7.3618e-01, -1.5987e-02, -9.0124e-02, -9.9919e-01,  9.9956e-01,\n",
       "         -9.9981e-01,  3.0518e-01, -9.9987e-01,  4.2324e-02, -9.5212e-01,\n",
       "         -9.9992e-01, -1.2736e-01,  7.2559e-01,  9.9966e-01,  9.9990e-01,\n",
       "          4.8717e-02,  1.4779e-02, -8.6559e-02,  3.7328e-02, -9.9964e-01,\n",
       "          2.9536e-01, -5.3025e-01,  1.4890e-01, -6.3320e-02,  9.9988e-01,\n",
       "          9.9817e-01, -8.0672e-01, -9.9984e-01,  9.9911e-01, -1.5556e-01,\n",
       "         -2.4956e-04,  1.1154e-01,  1.3920e-01, -6.3830e-02,  5.3090e-03,\n",
       "         -1.0000e+00, -9.9969e-01,  1.0000e+00,  9.7927e-01,  9.9327e-01,\n",
       "          9.7617e-01,  9.0341e-01, -2.0637e-01,  7.3159e-02, -9.9898e-01,\n",
       "         -9.9951e-01,  1.8288e-01,  2.7511e-02, -1.0000e+00,  9.9861e-01,\n",
       "         -9.9994e-01,  1.8752e-02, -1.1901e-01,  9.9946e-01,  1.0000e+00,\n",
       "         -9.5108e-02, -1.0000e+00, -9.9996e-01, -9.7404e-01,  1.3960e-01,\n",
       "          9.9964e-01,  2.4640e-01,  1.4689e-01, -8.7339e-02, -3.4547e-01,\n",
       "          9.9985e-01, -8.9026e-01, -4.5960e-02, -8.6028e-01,  1.0000e+00,\n",
       "         -1.3172e-01, -1.0000e+00,  9.8186e-01, -9.9985e-01, -2.5657e-01,\n",
       "          1.3393e-01,  9.9633e-01, -4.1474e-01,  8.5262e-01,  9.9997e-01,\n",
       "         -9.9990e-01,  9.9990e-01, -9.9998e-01,  8.2329e-01,  1.0000e+00,\n",
       "         -1.0000e+00,  1.2235e-01, -1.0000e+00, -9.9945e-01,  6.3550e-02,\n",
       "          5.7964e-02, -8.1631e-02,  9.9991e-01, -1.0000e+00, -1.0000e+00,\n",
       "          1.0858e-01, -9.9952e-01, -5.7087e-01,  9.9944e-01, -1.2120e-01,\n",
       "          9.9821e-01, -3.0262e-02, -5.7592e-02,  3.9226e-02,  5.7246e-01,\n",
       "          1.0000e+00,  2.6554e-01,  5.0320e-01, -1.0000e+00,  9.9991e-01,\n",
       "         -8.6385e-03,  8.6550e-02,  1.0000e+00, -9.4948e-02, -3.1648e-01,\n",
       "         -3.9531e-02, -1.0000e+00, -2.3463e-01,  2.8024e-01, -9.8999e-01,\n",
       "          9.9085e-01,  3.6010e-02,  2.3165e-03, -1.3011e-01, -1.4445e-01,\n",
       "         -9.9996e-01,  9.1007e-03, -9.9995e-01,  9.9998e-01, -9.9908e-01,\n",
       "         -7.8110e-02, -1.4725e-01, -1.0074e-01, -1.4981e-01,  9.9998e-01,\n",
       "          1.0000e+00, -9.9997e-01, -1.3312e-01,  9.9999e-01, -1.4962e-01,\n",
       "          9.9966e-01, -1.0000e+00,  8.9529e-02, -1.8057e-01,  3.2512e-04,\n",
       "          9.9999e-01, -1.8597e-01,  5.9983e-02,  9.9507e-01, -1.0000e+00,\n",
       "         -9.9925e-01,  1.8951e-01,  1.5143e-02, -8.1227e-02, -1.0000e+00,\n",
       "          4.5069e-02,  9.4022e-01, -4.3265e-02, -1.0000e+00,  2.3922e-01,\n",
       "         -1.0000e+00, -7.7973e-02,  9.9962e-01,  7.6672e-01,  1.0000e+00,\n",
       "          1.1539e-01,  3.7578e-02, -4.2669e-02, -1.0000e+00, -9.4919e-01,\n",
       "         -5.2127e-02,  1.1060e-01, -9.7984e-01, -9.6713e-02, -2.2451e-01,\n",
       "         -4.2680e-01, -9.9836e-01, -8.5923e-03,  8.9472e-01,  2.0756e-02,\n",
       "         -4.0297e-01, -2.1829e-01,  1.1976e-02, -9.9530e-01,  8.9872e-02,\n",
       "          1.4433e-02,  6.5843e-01, -9.9989e-01,  8.9800e-03, -3.4899e-01,\n",
       "          9.9994e-01, -1.0000e+00,  1.0501e-01, -9.9995e-01, -1.1424e-02,\n",
       "         -2.9408e-03, -9.2904e-02, -2.1374e-02,  2.5580e-01, -5.0770e-01,\n",
       "         -9.9951e-01,  1.0000e+00, -1.0000e+00, -1.0000e+00,  1.0000e+00,\n",
       "         -3.1199e-01, -9.9991e-01,  1.1452e-01,  9.7661e-03,  2.1687e-01,\n",
       "          7.9324e-02, -9.0908e-02, -3.0775e-01, -6.3040e-02, -9.9997e-01,\n",
       "          8.1482e-01, -1.7134e-01, -9.9178e-01,  7.2414e-03,  3.6459e-02,\n",
       "         -9.9999e-01,  1.0000e+00,  1.0000e+00,  1.0000e+00, -1.0000e+00,\n",
       "         -7.7369e-02,  8.9752e-02,  1.0000e+00,  8.1708e-03,  5.2400e-02,\n",
       "          9.9949e-01,  9.9979e-01,  3.9056e-02,  5.6418e-01, -7.2911e-02,\n",
       "         -5.3782e-03,  6.3502e-02,  7.6520e-02, -7.8733e-01, -9.9970e-01,\n",
       "         -9.1909e-02, -9.9998e-01, -9.9975e-01,  9.9942e-01, -4.9157e-02,\n",
       "          9.9998e-01,  1.2678e-01,  1.7930e-01, -1.6598e-01,  9.9977e-01,\n",
       "         -9.9925e-01, -1.9588e-01, -9.9997e-01,  3.2896e-02, -1.0000e+00,\n",
       "         -9.9998e-01, -1.7037e-01,  4.0505e-02, -9.9997e-01, -9.9080e-01,\n",
       "         -3.4059e-04, -9.9998e-01,  9.7166e-01, -9.9957e-01, -9.9952e-01,\n",
       "         -9.9984e-01, -7.6790e-01,  9.5035e-03, -1.2322e-03,  9.9935e-01,\n",
       "         -9.1542e-01,  9.9992e-01, -1.7458e-01,  8.5998e-01, -1.2466e-01,\n",
       "          3.2337e-03,  1.2082e-01, -9.9269e-01, -8.1398e-01, -9.9999e-01,\n",
       "          7.1634e-01, -9.9999e-01,  4.0742e-02,  1.0000e+00,  1.0000e+00,\n",
       "         -9.9915e-01, -1.0000e+00,  9.9300e-01,  8.0392e-02,  1.0000e+00,\n",
       "         -1.0212e-01, -9.9999e-01, -1.0000e+00,  5.8561e-03,  1.0885e-01,\n",
       "          1.0000e+00, -1.0018e-02,  9.9639e-01, -1.3854e-01, -3.2615e-01,\n",
       "          1.8221e-01,  1.3862e-01, -5.2194e-02,  2.9646e-02,  1.2015e-02,\n",
       "          9.9998e-01, -4.4049e-01,  1.0000e+00]]), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f8fc12f-4739-4ec5-9e8d-7459085c1e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 768])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (batch_size, sequence_length, hidden_size).\n",
    "\n",
    "# last_hidden_state: This tensor contains the hidden states of the model's last layer. \n",
    "# In the context of BERT-based models, these hidden states represent the contextualized embeddings of each input token. \n",
    "# The tensor's shape is (batch_size, sequence_length, hidden_size). \\\n",
    "# In your case, it seems to be a single sequence with a length of 5 tokens and a hidden size of 768.\n",
    "\n",
    "# pooler_output: This tensor contains the pooled representation of the entire sequence, typically used as a representation \n",
    "# of the entire input sequence. The tensor's shape is (batch_size, hidden_size), and in your case, it's a vector with a size of 768.\n",
    "outputs['last_hidden_state'].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
